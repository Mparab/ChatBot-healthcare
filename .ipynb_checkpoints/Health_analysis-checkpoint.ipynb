{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee50c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25d974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         diseases  anxiety and nervousness  depression  shortness of breath  \\\n",
      "0  panic disorder                        1           0                    1   \n",
      "1  panic disorder                        0           0                    1   \n",
      "2  panic disorder                        1           1                    1   \n",
      "3  panic disorder                        1           0                    0   \n",
      "4  panic disorder                        1           1                    0   \n",
      "\n",
      "   depressive or psychotic symptoms  sharp chest pain  dizziness  insomnia  \\\n",
      "0                                 1                 0          0         0   \n",
      "1                                 1                 0          1         1   \n",
      "2                                 1                 0          1         1   \n",
      "3                                 1                 0          1         1   \n",
      "4                                 0                 0          0         1   \n",
      "\n",
      "   abnormal involuntary movements  chest tightness  ...  \\\n",
      "0                               0                1  ...   \n",
      "1                               0                0  ...   \n",
      "2                               0                0  ...   \n",
      "3                               1                0  ...   \n",
      "4                               1                1  ...   \n",
      "\n",
      "   stuttering or stammering  problems with orgasm  nose deformity  \\\n",
      "0                         0                     0               0   \n",
      "1                         0                     0               0   \n",
      "2                         0                     0               0   \n",
      "3                         0                     0               0   \n",
      "4                         0                     0               0   \n",
      "\n",
      "   lump over jaw  sore in nose  hip weakness  back swelling  \\\n",
      "0              0             0             0              0   \n",
      "1              0             0             0              0   \n",
      "2              0             0             0              0   \n",
      "3              0             0             0              0   \n",
      "4              0             0             0              0   \n",
      "\n",
      "   ankle stiffness or tightness  ankle weakness  neck weakness  \n",
      "0                             0               0              0  \n",
      "1                             0               0              0  \n",
      "2                             0               0              0  \n",
      "3                             0               0              0  \n",
      "4                             0               0              0  \n",
      "\n",
      "[5 rows x 378 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"/Users/mithilrsh/Desktop/Zidioproject3/Final_Augmented_dataset_Diseases_and_Symptoms.csv\")\n",
    "\n",
    "# View the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6725d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diseases                            0\n",
      "anxiety and nervousness             0\n",
      "depression                          0\n",
      "shortness of breath                 0\n",
      "depressive or psychotic symptoms    0\n",
      "                                   ..\n",
      "hip weakness                        0\n",
      "back swelling                       0\n",
      "ankle stiffness or tightness        0\n",
      "ankle weakness                      0\n",
      "neck weakness                       0\n",
      "Length: 378, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a22915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"diseases\"] = le.fit_transform(df[\"diseases\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a330f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"diseases\", axis=1)\n",
    "y = df[\"diseases\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d972ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c986a5",
   "metadata": {},
   "source": [
    "Train the model using random forest and find accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3570340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23025370021664743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use fewer trees to reduce RAM usage\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fbb58",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0b3d1",
   "metadata": {},
   "source": [
    "Train for better accuracy this accuracy is not enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f8fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes (great for binary inputs)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68d6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (multi-class)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ea8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree with depth limit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9769c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Select top 100 symptoms\n",
    "selector = SelectKBest(score_func=chi2, k=100)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Use this new X_new in place of X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43002f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diseases\n",
      "165    1219\n",
      "766    1218\n",
      "481    1218\n",
      "138    1217\n",
      "669    1216\n",
      "       ... \n",
      "728       1\n",
      "626       1\n",
      "502       1\n",
      "340       1\n",
      "487       1\n",
      "Name: count, Length: 773, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"diseases\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77744aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining diseases: 527\n"
     ]
    }
   ],
   "source": [
    "# Filter out diseases with fewer than 50 samples\n",
    "disease_counts = df[\"diseases\"].value_counts()\n",
    "common_diseases = disease_counts[disease_counts >= 50].index\n",
    "\n",
    "df_filtered = df[df[\"diseases\"].isin(common_diseases)]\n",
    "print(\"Remaining diseases:\", df_filtered[\"diseases\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6248bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered.drop(\"diseases\", axis=1)\n",
    "y = df_filtered[\"diseases\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17aef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (642413, 377) (642413,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "print(\"New shape:\", X_resampled.shape, y_resampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac8ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9189386922783559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       236\n",
      "           1       0.98      0.98      0.98       245\n",
      "           2       0.93      0.96      0.94       258\n",
      "           4       0.96      0.94      0.95       230\n",
      "           7       0.90      0.96      0.93       282\n",
      "           8       0.82      0.87      0.85       247\n",
      "           9       0.83      0.71      0.77       270\n",
      "          10       0.94      0.90      0.92       256\n",
      "          11       0.76      0.67      0.71       248\n",
      "          12       0.73      0.72      0.72       245\n",
      "          14       0.70      0.71      0.70       266\n",
      "          15       0.98      0.95      0.96       229\n",
      "          16       0.81      0.88      0.85       229\n",
      "          17       0.90      0.90      0.90       233\n",
      "          18       0.93      0.91      0.92       251\n",
      "          19       0.85      0.86      0.85       242\n",
      "          20       0.95      0.93      0.94       260\n",
      "          21       0.99      1.00      1.00       230\n",
      "          22       0.85      0.89      0.86       235\n",
      "          25       0.88      0.94      0.91       228\n",
      "          26       0.93      0.95      0.94       226\n",
      "          27       0.97      0.97      0.97       233\n",
      "          28       0.99      0.97      0.98       216\n",
      "          29       0.96      0.93      0.95       235\n",
      "          31       0.84      0.99      0.91       255\n",
      "          32       0.96      0.96      0.96       250\n",
      "          35       1.00      1.00      1.00       215\n",
      "          36       0.97      0.99      0.98       260\n",
      "          38       0.98      0.99      0.98       254\n",
      "          39       0.99      0.99      0.99       235\n",
      "          42       0.96      0.92      0.94       216\n",
      "          43       0.89      0.94      0.91       214\n",
      "          44       0.98      0.90      0.93       248\n",
      "          45       0.96      0.95      0.95       240\n",
      "          47       0.93      0.98      0.96       229\n",
      "          48       0.99      1.00      0.99       251\n",
      "          49       0.84      0.88      0.86       247\n",
      "          50       0.92      0.86      0.89       269\n",
      "          51       0.94      0.92      0.93       235\n",
      "          52       0.99      0.95      0.97       231\n",
      "          53       0.90      0.91      0.91       254\n",
      "          55       0.82      0.80      0.81       261\n",
      "          56       0.72      0.72      0.72       250\n",
      "          57       0.85      0.91      0.88       243\n",
      "          58       0.86      0.87      0.87       231\n",
      "          59       0.93      1.00      0.97       255\n",
      "          60       0.79      0.88      0.84       236\n",
      "          61       0.95      0.93      0.94       242\n",
      "          62       0.83      0.82      0.83       231\n",
      "          63       0.92      0.98      0.95       246\n",
      "          65       0.91      0.89      0.90       259\n",
      "          66       0.95      0.97      0.96       236\n",
      "          67       0.95      1.00      0.97       253\n",
      "          69       0.98      0.99      0.99       232\n",
      "          70       0.98      0.95      0.96       237\n",
      "          71       0.93      0.98      0.96       217\n",
      "          72       0.98      0.96      0.97       258\n",
      "          73       0.99      0.90      0.94       239\n",
      "          74       0.90      0.92      0.91       226\n",
      "          75       0.68      0.73      0.71       242\n",
      "          77       0.97      1.00      0.98       249\n",
      "          78       0.73      0.82      0.77       253\n",
      "          79       0.94      0.96      0.95       233\n",
      "          80       0.81      0.75      0.78       212\n",
      "          82       0.92      1.00      0.96       230\n",
      "          83       1.00      0.95      0.98       230\n",
      "          85       0.92      0.91      0.92       238\n",
      "          86       0.95      0.96      0.96       223\n",
      "          89       1.00      1.00      1.00       249\n",
      "          90       0.97      1.00      0.98       248\n",
      "          92       0.99      1.00      0.99       228\n",
      "          93       0.99      0.95      0.97       243\n",
      "          94       0.91      0.85      0.88       237\n",
      "          95       0.88      0.89      0.88       236\n",
      "          97       0.97      0.95      0.96       245\n",
      "          98       0.97      0.92      0.95       235\n",
      "          99       0.97      0.94      0.95       244\n",
      "         101       0.81      0.69      0.75       241\n",
      "         102       0.87      0.99      0.93       244\n",
      "         103       1.00      0.99      0.99       263\n",
      "         105       0.92      0.96      0.94       228\n",
      "         106       0.93      0.98      0.96       244\n",
      "         107       1.00      1.00      1.00       268\n",
      "         108       0.97      0.98      0.97       252\n",
      "         110       0.92      0.94      0.93       265\n",
      "         111       0.92      0.90      0.91       230\n",
      "         112       0.98      0.98      0.98       271\n",
      "         113       0.85      0.95      0.90       235\n",
      "         114       0.85      0.75      0.79       251\n",
      "         115       0.96      0.94      0.95       255\n",
      "         117       0.94      0.92      0.93       247\n",
      "         118       0.89      1.00      0.94       262\n",
      "         119       0.96      0.95      0.96       243\n",
      "         120       0.93      0.85      0.89       250\n",
      "         121       0.82      0.80      0.81       263\n",
      "         124       0.92      0.93      0.93       229\n",
      "         125       0.67      0.71      0.69       235\n",
      "         126       0.90      0.95      0.92       234\n",
      "         127       0.91      0.93      0.92       201\n",
      "         128       0.97      0.98      0.97       230\n",
      "         129       0.96      0.92      0.94       257\n",
      "         130       0.87      0.91      0.89       227\n",
      "         132       0.99      0.99      0.99       231\n",
      "         133       1.00      0.99      0.99       246\n",
      "         134       0.96      0.99      0.98       263\n",
      "         135       0.93      0.97      0.95       236\n",
      "         137       0.86      0.88      0.87       236\n",
      "         138       0.92      0.81      0.86       247\n",
      "         139       1.00      0.96      0.98       243\n",
      "         140       0.95      0.92      0.94       245\n",
      "         141       0.95      0.95      0.95       264\n",
      "         144       0.91      0.92      0.91       230\n",
      "         145       0.90      0.90      0.90       232\n",
      "         146       0.88      0.96      0.92       228\n",
      "         147       0.88      0.87      0.88       246\n",
      "         149       0.81      0.82      0.81       223\n",
      "         151       0.91      0.80      0.85       251\n",
      "         152       0.72      0.72      0.72       244\n",
      "         153       0.65      0.51      0.57       250\n",
      "         154       0.89      0.96      0.92       252\n",
      "         155       0.97      0.98      0.97       267\n",
      "         156       0.88      0.86      0.87       235\n",
      "         157       0.88      0.84      0.86       249\n",
      "         158       0.96      1.00      0.98       241\n",
      "         165       0.84      0.70      0.77       250\n",
      "         166       0.96      0.92      0.94       269\n",
      "         168       0.97      0.99      0.98       234\n",
      "         169       0.71      0.72      0.72       245\n",
      "         170       0.96      0.91      0.94       269\n",
      "         171       0.92      0.92      0.92       248\n",
      "         173       0.94      0.89      0.91       274\n",
      "         174       0.78      0.65      0.71       233\n",
      "         175       0.85      0.86      0.85       229\n",
      "         176       0.98      0.92      0.95       265\n",
      "         177       0.95      1.00      0.97       225\n",
      "         180       0.98      0.95      0.96       263\n",
      "         182       1.00      0.97      0.99       239\n",
      "         183       0.65      0.70      0.67       245\n",
      "         184       0.98      0.98      0.98       249\n",
      "         186       0.97      0.99      0.98       243\n",
      "         192       0.93      1.00      0.96       254\n",
      "         195       0.99      1.00      0.99       269\n",
      "         196       0.88      0.83      0.86       253\n",
      "         197       0.91      0.91      0.91       235\n",
      "         198       0.97      0.99      0.98       252\n",
      "         199       0.90      0.87      0.89       228\n",
      "         200       0.94      0.98      0.96       237\n",
      "         201       0.86      0.90      0.88       262\n",
      "         202       0.95      0.90      0.93       252\n",
      "         203       0.76      0.81      0.79       239\n",
      "         204       0.99      0.99      0.99       238\n",
      "         205       0.99      0.95      0.97       246\n",
      "         206       0.97      0.96      0.97       226\n",
      "         207       0.73      0.50      0.59       257\n",
      "         209       0.90      0.94      0.92       273\n",
      "         210       0.93      0.89      0.91       239\n",
      "         211       0.92      0.93      0.93       243\n",
      "         212       0.90      0.87      0.88       258\n",
      "         213       0.96      0.99      0.97       250\n",
      "         214       0.79      0.95      0.86       246\n",
      "         216       0.86      0.70      0.77       245\n",
      "         220       0.93      0.98      0.95       242\n",
      "         221       0.71      0.96      0.81       261\n",
      "         222       0.98      0.97      0.97       248\n",
      "         224       0.97      0.97      0.97       261\n",
      "         225       0.96      1.00      0.98       251\n",
      "         226       0.97      0.98      0.98       219\n",
      "         228       1.00      0.98      0.99       244\n",
      "         230       0.98      0.93      0.95       226\n",
      "         231       0.95      0.90      0.92       249\n",
      "         233       0.98      1.00      0.99       241\n",
      "         235       0.97      0.89      0.93       245\n",
      "         236       0.98      0.99      0.99       238\n",
      "         237       0.97      0.93      0.95       274\n",
      "         238       0.98      0.99      0.99       239\n",
      "         239       0.99      0.99      0.99       236\n",
      "         241       0.98      1.00      0.99       251\n",
      "         244       1.00      0.96      0.98       229\n",
      "         246       0.89      0.86      0.88       262\n",
      "         249       0.96      0.91      0.93       259\n",
      "         250       0.93      0.86      0.90       229\n",
      "         252       0.97      0.94      0.95       235\n",
      "         254       0.72      0.95      0.82       228\n",
      "         255       0.98      0.99      0.99       254\n",
      "         257       0.96      1.00      0.98       233\n",
      "         260       0.96      0.93      0.95       224\n",
      "         261       1.00      0.97      0.98       241\n",
      "         264       0.89      0.87      0.88       235\n",
      "         265       0.99      1.00      0.99       259\n",
      "         266       0.97      0.96      0.97       235\n",
      "         268       1.00      0.94      0.97       233\n",
      "         269       0.94      0.98      0.96       252\n",
      "         270       0.98      0.95      0.97       282\n",
      "         271       0.96      1.00      0.98       234\n",
      "         272       0.91      1.00      0.95       256\n",
      "         273       0.99      0.98      0.98       254\n",
      "         276       0.83      0.70      0.76       237\n",
      "         277       0.81      0.76      0.78       242\n",
      "         280       0.78      0.83      0.81       263\n",
      "         281       0.99      0.99      0.99       252\n",
      "         283       0.91      0.86      0.88       252\n",
      "         284       0.91      0.93      0.92       247\n",
      "         285       0.95      0.92      0.94       268\n",
      "         286       0.94      0.89      0.92       232\n",
      "         287       0.86      0.90      0.88       266\n",
      "         288       0.96      0.98      0.97       253\n",
      "         290       0.80      0.76      0.78       232\n",
      "         292       0.99      1.00      1.00       230\n",
      "         293       0.99      0.98      0.99       221\n",
      "         294       0.95      0.92      0.93       239\n",
      "         296       0.97      0.98      0.97       231\n",
      "         297       0.99      1.00      1.00       228\n",
      "         298       0.87      0.78      0.83       244\n",
      "         299       0.96      1.00      0.98       262\n",
      "         302       1.00      0.99      0.99       238\n",
      "         303       0.98      0.98      0.98       281\n",
      "         304       0.97      0.97      0.97       239\n",
      "         305       0.98      0.95      0.96       260\n",
      "         306       0.95      0.82      0.88       236\n",
      "         308       0.97      0.91      0.94       238\n",
      "         309       0.95      0.93      0.94       232\n",
      "         311       0.86      0.82      0.84       262\n",
      "         313       0.97      1.00      0.99       249\n",
      "         314       0.96      0.98      0.97       245\n",
      "         318       0.95      0.89      0.91       235\n",
      "         320       0.99      0.98      0.98       230\n",
      "         321       0.75      0.77      0.76       222\n",
      "         322       0.97      0.98      0.98       270\n",
      "         323       0.97      0.92      0.94       224\n",
      "         324       0.98      0.98      0.98       252\n",
      "         329       1.00      1.00      1.00       258\n",
      "         333       1.00      0.98      0.99       223\n",
      "         334       0.93      0.99      0.96       242\n",
      "         335       0.87      0.90      0.88       240\n",
      "         336       0.88      0.93      0.90       220\n",
      "         339       0.93      0.93      0.93       256\n",
      "         342       0.99      0.93      0.96       238\n",
      "         344       0.88      1.00      0.94       248\n",
      "         345       0.95      0.99      0.97       248\n",
      "         347       0.99      1.00      0.99       241\n",
      "         348       0.96      0.98      0.97       242\n",
      "         351       0.98      0.96      0.97       248\n",
      "         352       0.92      0.94      0.93       235\n",
      "         353       0.95      0.89      0.92       216\n",
      "         355       0.99      0.97      0.98       212\n",
      "         356       0.95      0.96      0.95       263\n",
      "         357       0.99      0.97      0.98       252\n",
      "         358       0.91      0.85      0.88       234\n",
      "         359       0.88      1.00      0.94       249\n",
      "         360       0.89      0.87      0.88       249\n",
      "         361       1.00      1.00      1.00       236\n",
      "         362       0.92      0.87      0.90       235\n",
      "         363       0.87      0.87      0.87       255\n",
      "         364       0.96      0.93      0.95       248\n",
      "         365       0.76      0.87      0.81       269\n",
      "         366       0.94      0.89      0.91       236\n",
      "         367       0.93      0.97      0.95       250\n",
      "         369       0.64      0.63      0.63       235\n",
      "         370       0.99      0.99      0.99       219\n",
      "         371       0.99      0.93      0.96       233\n",
      "         372       0.96      1.00      0.98       249\n",
      "         373       0.96      1.00      0.98       233\n",
      "         374       0.96      1.00      0.98       245\n",
      "         375       0.99      0.93      0.96       263\n",
      "         376       1.00      0.99      1.00       226\n",
      "         378       0.88      0.97      0.93       255\n",
      "         380       0.89      0.96      0.92       252\n",
      "         381       0.96      0.93      0.95       251\n",
      "         382       0.98      0.94      0.96       255\n",
      "         384       0.97      0.97      0.97       224\n",
      "         385       0.92      0.92      0.92       242\n",
      "         387       0.90      0.90      0.90       234\n",
      "         388       0.70      0.93      0.80       250\n",
      "         390       0.88      0.84      0.86       255\n",
      "         391       0.96      1.00      0.98       237\n",
      "         392       0.92      0.92      0.92       258\n",
      "         393       0.96      0.92      0.94       237\n",
      "         395       0.92      0.86      0.89       244\n",
      "         397       0.93      0.83      0.88       248\n",
      "         398       0.99      0.97      0.98       196\n",
      "         399       1.00      0.95      0.97       217\n",
      "         400       0.89      0.95      0.92       268\n",
      "         401       1.00      0.95      0.97       259\n",
      "         402       0.98      0.98      0.98       241\n",
      "         403       0.97      0.99      0.98       268\n",
      "         404       0.99      0.97      0.98       229\n",
      "         407       0.96      0.97      0.97       258\n",
      "         409       0.90      0.98      0.94       239\n",
      "         410       0.68      0.63      0.66       238\n",
      "         411       1.00      0.99      1.00       254\n",
      "         412       0.99      0.96      0.97       248\n",
      "         413       1.00      1.00      1.00       218\n",
      "         414       0.98      0.96      0.97       272\n",
      "         415       0.92      0.96      0.94       228\n",
      "         417       0.86      0.98      0.91       265\n",
      "         418       1.00      0.98      0.99       235\n",
      "         420       0.98      0.96      0.97       239\n",
      "         421       0.98      0.96      0.97       265\n",
      "         423       0.98      0.96      0.97       257\n",
      "         424       0.97      0.97      0.97       244\n",
      "         425       0.95      1.00      0.97       209\n",
      "         427       0.99      0.99      0.99       265\n",
      "         428       0.99      0.97      0.98       255\n",
      "         430       0.98      0.97      0.97       264\n",
      "         432       0.99      1.00      0.99       268\n",
      "         433       0.88      0.71      0.78       251\n",
      "         436       0.99      1.00      1.00       231\n",
      "         437       0.97      0.97      0.97       237\n",
      "         438       0.79      0.67      0.72       230\n",
      "         440       0.90      0.99      0.94       235\n",
      "         442       0.90      0.97      0.94       225\n",
      "         443       0.96      0.95      0.96       264\n",
      "         445       0.95      0.95      0.95       243\n",
      "         446       0.96      1.00      0.98       214\n",
      "         449       0.94      0.95      0.95       258\n",
      "         450       0.94      0.94      0.94       248\n",
      "         451       0.91      0.93      0.92       263\n",
      "         452       0.97      0.97      0.97       233\n",
      "         453       0.88      0.82      0.85       234\n",
      "         454       0.94      0.92      0.93       272\n",
      "         455       0.97      0.95      0.96       216\n",
      "         457       0.97      0.98      0.98       244\n",
      "         458       0.98      1.00      0.99       241\n",
      "         459       0.94      0.94      0.94       251\n",
      "         461       0.88      0.90      0.89       230\n",
      "         463       1.00      0.99      1.00       269\n",
      "         467       0.92      0.88      0.90       234\n",
      "         468       0.98      0.89      0.93       228\n",
      "         469       0.99      0.95      0.97       251\n",
      "         470       0.98      0.98      0.98       252\n",
      "         473       0.98      0.94      0.96       237\n",
      "         474       0.69      0.77      0.73       237\n",
      "         477       0.94      0.85      0.89       256\n",
      "         478       0.97      0.98      0.97       238\n",
      "         479       0.66      0.60      0.63       239\n",
      "         481       0.92      0.77      0.84       243\n",
      "         483       0.96      0.93      0.95       231\n",
      "         484       0.99      0.99      0.99       222\n",
      "         486       0.93      0.90      0.91       224\n",
      "         504       0.99      0.98      0.99       225\n",
      "         508       0.96      0.93      0.94       258\n",
      "         511       0.93      0.92      0.93       232\n",
      "         512       0.99      0.96      0.97       255\n",
      "         513       0.98      0.99      0.98       238\n",
      "         514       0.97      0.97      0.97       228\n",
      "         515       0.96      0.93      0.94       246\n",
      "         516       0.94      1.00      0.97       286\n",
      "         517       0.96      0.98      0.97       246\n",
      "         518       1.00      0.99      0.99       274\n",
      "         519       0.99      0.99      0.99       268\n",
      "         520       0.97      0.89      0.93       258\n",
      "         521       0.91      0.79      0.85       234\n",
      "         524       0.87      0.86      0.87       249\n",
      "         525       0.99      1.00      1.00       258\n",
      "         526       0.96      0.89      0.92       220\n",
      "         527       0.94      0.92      0.93       261\n",
      "         528       0.96      0.97      0.96       248\n",
      "         529       0.99      0.96      0.97       232\n",
      "         530       1.00      0.98      0.99       264\n",
      "         531       0.94      0.95      0.95       239\n",
      "         532       1.00      1.00      1.00       232\n",
      "         534       0.97      0.98      0.97       226\n",
      "         535       0.98      0.99      0.99       253\n",
      "         536       0.93      0.82      0.87       236\n",
      "         537       0.87      0.78      0.82       230\n",
      "         539       0.93      0.84      0.89       248\n",
      "         540       0.96      0.93      0.94       208\n",
      "         542       0.96      0.97      0.97       253\n",
      "         543       0.96      0.99      0.98       273\n",
      "         544       0.97      0.97      0.97       228\n",
      "         545       0.95      0.89      0.92       246\n",
      "         546       1.00      0.96      0.98       231\n",
      "         547       0.92      0.95      0.93       253\n",
      "         548       0.99      0.97      0.98       229\n",
      "         549       0.90      0.95      0.92       264\n",
      "         550       0.54      0.52      0.53       242\n",
      "         553       0.97      1.00      0.98       257\n",
      "         554       0.99      0.99      0.99       240\n",
      "         556       0.98      1.00      0.99       259\n",
      "         559       0.83      1.00      0.90       252\n",
      "         562       0.99      0.99      0.99       243\n",
      "         563       0.95      0.93      0.94       240\n",
      "         565       0.75      0.68      0.71       248\n",
      "         566       0.92      0.98      0.94       244\n",
      "         567       1.00      0.99      0.99       275\n",
      "         571       1.00      0.98      0.99       233\n",
      "         574       0.91      0.90      0.91       261\n",
      "         576       0.82      0.97      0.89       248\n",
      "         577       0.95      0.98      0.96       234\n",
      "         578       1.00      0.98      0.99       244\n",
      "         580       0.97      0.99      0.98       234\n",
      "         581       0.56      0.55      0.56       232\n",
      "         582       0.98      0.98      0.98       237\n",
      "         583       0.94      0.97      0.95       247\n",
      "         584       0.98      0.98      0.98       237\n",
      "         586       0.89      0.94      0.91       247\n",
      "         589       0.97      0.93      0.95       230\n",
      "         590       1.00      1.00      1.00       224\n",
      "         591       0.97      1.00      0.98       255\n",
      "         592       0.85      0.97      0.91       301\n",
      "         595       0.96      1.00      0.98       218\n",
      "         598       0.94      0.93      0.93       254\n",
      "         599       0.94      1.00      0.97       257\n",
      "         600       0.93      0.91      0.92       251\n",
      "         601       0.89      1.00      0.94       225\n",
      "         604       0.77      0.76      0.77       231\n",
      "         605       0.98      0.98      0.98       243\n",
      "         606       0.64      0.53      0.58       258\n",
      "         607       0.81      0.95      0.87       218\n",
      "         608       0.95      0.94      0.94       249\n",
      "         609       0.97      0.95      0.96       236\n",
      "         610       0.99      0.96      0.97       235\n",
      "         611       0.80      0.94      0.87       282\n",
      "         612       0.96      0.94      0.95       233\n",
      "         614       0.73      0.66      0.70       238\n",
      "         616       0.98      0.93      0.95       272\n",
      "         619       0.92      0.93      0.93       246\n",
      "         620       0.96      0.97      0.97       262\n",
      "         621       0.64      0.75      0.69       231\n",
      "         622       0.93      0.91      0.92       258\n",
      "         625       1.00      0.96      0.98       254\n",
      "         627       0.91      0.85      0.88       229\n",
      "         628       0.93      0.97      0.95       236\n",
      "         629       0.90      0.95      0.92       221\n",
      "         630       0.97      0.97      0.97       225\n",
      "         631       0.98      1.00      0.99       238\n",
      "         632       0.68      0.88      0.77       232\n",
      "         633       0.95      0.95      0.95       241\n",
      "         634       0.65      0.61      0.63       264\n",
      "         635       0.97      0.95      0.96       239\n",
      "         637       0.92      0.94      0.93       252\n",
      "         638       0.96      1.00      0.98       247\n",
      "         640       0.97      0.93      0.95       225\n",
      "         641       0.94      0.94      0.94       250\n",
      "         642       0.89      0.87      0.88       243\n",
      "         643       0.50      0.45      0.47       243\n",
      "         644       0.95      0.86      0.90       255\n",
      "         645       0.95      0.92      0.94       250\n",
      "         646       0.86      0.98      0.91       253\n",
      "         647       1.00      0.99      0.99       250\n",
      "         648       0.99      0.97      0.98       234\n",
      "         649       0.84      0.80      0.82       248\n",
      "         650       0.98      1.00      0.99       247\n",
      "         651       0.95      0.94      0.95       236\n",
      "         652       0.84      0.79      0.82       241\n",
      "         653       0.96      0.98      0.97       262\n",
      "         654       0.72      0.70      0.71       254\n",
      "         655       0.49      0.58      0.53       233\n",
      "         656       0.52      0.49      0.50       234\n",
      "         657       0.42      0.31      0.36       236\n",
      "         658       0.98      0.98      0.98       256\n",
      "         659       0.76      0.78      0.77       218\n",
      "         660       0.91      0.94      0.92       242\n",
      "         661       0.98      1.00      0.99       248\n",
      "         662       0.98      1.00      0.99       247\n",
      "         664       1.00      1.00      1.00       223\n",
      "         665       0.73      0.63      0.67       254\n",
      "         667       0.92      0.94      0.93       229\n",
      "         668       0.87      0.91      0.89       241\n",
      "         669       0.72      0.67      0.69       241\n",
      "         670       0.85      0.74      0.79       251\n",
      "         672       0.93      0.89      0.91       241\n",
      "         673       0.97      1.00      0.99       234\n",
      "         674       0.91      0.98      0.95       256\n",
      "         675       0.98      0.89      0.93       228\n",
      "         676       0.99      0.95      0.97       231\n",
      "         677       1.00      1.00      1.00       277\n",
      "         678       0.96      0.86      0.90       253\n",
      "         679       0.98      0.96      0.97       273\n",
      "         681       0.99      0.93      0.96       244\n",
      "         682       0.92      0.95      0.93       241\n",
      "         683       0.95      0.99      0.97       275\n",
      "         684       0.79      0.87      0.83       220\n",
      "         688       0.98      1.00      0.99       239\n",
      "         689       0.97      0.97      0.97       236\n",
      "         690       0.71      0.68      0.70       234\n",
      "         691       0.93      0.98      0.95       242\n",
      "         692       0.94      0.91      0.92       241\n",
      "         693       0.99      0.96      0.97       253\n",
      "         695       1.00      1.00      1.00       253\n",
      "         696       0.98      0.99      0.98       238\n",
      "         698       0.94      0.96      0.95       230\n",
      "         699       0.99      0.97      0.98       253\n",
      "         700       0.83      0.83      0.83       242\n",
      "         701       1.00      1.00      1.00       242\n",
      "         702       1.00      1.00      1.00       247\n",
      "         705       0.98      0.98      0.98       257\n",
      "         706       0.89      1.00      0.94       262\n",
      "         707       0.93      0.96      0.95       240\n",
      "         708       0.89      0.92      0.90       248\n",
      "         709       0.94      0.96      0.95       246\n",
      "         710       0.99      0.97      0.98       250\n",
      "         711       0.87      0.93      0.90       234\n",
      "         712       0.84      0.85      0.85       248\n",
      "         713       0.96      0.99      0.98       249\n",
      "         715       0.99      1.00      1.00       234\n",
      "         717       0.92      0.97      0.95       262\n",
      "         718       0.96      0.95      0.96       265\n",
      "         721       0.97      0.89      0.93       231\n",
      "         723       0.95      0.97      0.96       241\n",
      "         724       0.94      0.97      0.96       235\n",
      "         729       0.90      0.92      0.91       253\n",
      "         730       0.89      0.99      0.93       230\n",
      "         731       0.91      0.96      0.93       255\n",
      "         733       0.96      0.90      0.93       262\n",
      "         734       0.95      0.93      0.94       244\n",
      "         735       0.74      0.78      0.76       241\n",
      "         736       0.90      0.88      0.89       232\n",
      "         737       0.96      0.98      0.97       247\n",
      "         739       0.89      0.95      0.92       228\n",
      "         742       0.75      0.77      0.76       239\n",
      "         743       0.94      0.91      0.92       256\n",
      "         744       0.95      1.00      0.97       244\n",
      "         745       0.98      0.80      0.88       243\n",
      "         747       0.99      0.97      0.98       248\n",
      "         748       0.96      0.95      0.96       247\n",
      "         749       0.99      0.99      0.99       227\n",
      "         750       0.97      0.98      0.98       235\n",
      "         753       0.94      0.91      0.92       245\n",
      "         755       0.88      0.79      0.83       248\n",
      "         757       0.96      1.00      0.98       257\n",
      "         759       0.57      0.67      0.61       227\n",
      "         761       0.92      1.00      0.96       226\n",
      "         765       0.95      0.97      0.96       231\n",
      "         766       0.92      0.91      0.91       246\n",
      "         768       0.92      0.93      0.93       233\n",
      "         771       0.95      0.97      0.96       237\n",
      "\n",
      "    accuracy                           0.92    128483\n",
      "   macro avg       0.92      0.92      0.92    128483\n",
      "weighted avg       0.92      0.92      0.92    128483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e88b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a tiny model for testing\n",
    "small_model = RandomForestClassifier(n_estimators=10)\n",
    "small_model.fit(X_train[:100], y_train[:100])  # just a slice\n",
    "\n",
    "# Try saving this\n",
    "with open(\"test_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(small_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c57962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Small model and label encoder saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# If your kernel is crashing due to large file size or memory usage, try these strategies:\n",
    "\n",
    "# 1. Load only a sample of the data for development/testing:\n",
    "import pandas as pd\n",
    "\n",
    "# Load only the first N rows (e.g., 5000) to reduce memory usage\n",
    "df_sample = pd.read_csv(\"/Users/mithilrsh/Desktop/Zidioproject3/Final_Augmented_dataset_Diseases_and_Symptoms.csv\", nrows=5000)\n",
    "\n",
    "# 2. Drop unnecessary columns early to save memory\n",
    "# For example, if there are columns you don't need:\n",
    "# df_sample = df_sample.drop(columns=[\"unnecessary_column1\", \"unnecessary_column2\"])\n",
    "\n",
    "# 3. Use a smaller model for initial testing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_sample[\"label\"] = le.fit_transform(df_sample[\"diseases\"])\n",
    "\n",
    "X = df_sample.drop(columns=[\"diseases\", \"label\"])\n",
    "y = df_sample[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use fewer trees to reduce memory and training time\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, \"disease_model_small.joblib\")\n",
    "joblib.dump(le, \"label_encoder_small.joblib\")\n",
    "\n",
    "print(\"✅ Small model and label encoder saved successfully.\")\n",
    "\n",
    "# 4. When ready, you can increase nrows or use the full dataset on a machine with more memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6ad9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved symptoms_list.joblib with 377 symptoms.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# ✅ Save the feature (symptom) list in order\n",
    "all_symptoms = X.columns.tolist()\n",
    "joblib.dump(all_symptoms, \"symptoms_list.joblib\")\n",
    "\n",
    "print(\"✅ Saved symptoms_list.joblib with\", len(all_symptoms), \"symptoms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abb31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"disease_model_small.joblib\")\n",
    "label_encoder = joblib.load(\"label_encoder_small.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd16d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"disease_model_small.joblib\")\n",
    "label_encoder = joblib.load(\"label_encoder_small.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b804fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
